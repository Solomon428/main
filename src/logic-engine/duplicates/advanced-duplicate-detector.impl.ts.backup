/**
 * CREDITORFLOW EMS - ADVANCED DUPLICATE DETECTION ENGINE
 * Version: 3.9.2
 * Lines: 618
 * Last Updated: 2024-01-22
 * 
 * ENTERPRISE-GRADE DUPLICATE DETECTION WITH:
 * - Multi-algorithm fuzzy matching (Levenshtein, Jaro-Winkler, Soundex, Metaphone)
 * - Machine learning-based similarity scoring (cosine similarity, TF-IDF)
 * - Temporal duplicate detection (time-based clustering)
 * - Supplier clustering analysis (entity resolution)
 * - Invoice grouping by PO/contract reference
 * - Confidence threshold configuration with adaptive tuning
 * - South African SARS compliance enforcement (duplicate invoice prohibition)
 * - Real-time duplicate screening during invoice ingestion
 * - Historical duplicate pattern analysis
 * - Audit trail for all duplicate determinations
 * - False positive reduction through contextual analysis
 * - Multi-field correlation scoring
 * - Cross-supplier duplicate detection (fraud pattern recognition)
 * - Partial duplicate handling (line item level matching)
 */

import { 
  DuplicateCheckInput, 
  DuplicateCheckResult, 
  DuplicateType, 
  DuplicateConfidence, 
  DuplicateDetectionMethod, 
  DuplicateRiskLevel, 
  DuplicateMitigationAction, 
  DuplicateAuditTrail, 
  DuplicatePattern, 
  DuplicateCluster, 
  DuplicateEvidence, 
  DuplicateResolutionStatus, 
  DuplicateInvestigationStatus, 
  DuplicateCaseStatus, 
  DuplicateEvidenceType, 
  DuplicateEvidenceSource, 
  DuplicateCaseResolution, 
  DuplicateLossEstimate, 
  DuplicateRecoveryStatus, 
  DuplicateRegulatoryImpact, 
  DuplicateNotificationRecipient, 
  DuplicateNotificationChannel, 
  DuplicateEscalationPath, 
  DuplicateEscalationLevel, 
  DuplicateSLATimeline, 
  DuplicateInvestigationTimeline, 
  DuplicateCaseTimeline, 
  DuplicateEvidenceChain, 
  DuplicateWitnessStatement, 
  DuplicateExpertOpinion, 
  DuplicateLegalOpinion, 
  DuplicateRegulatoryFiling, 
  DuplicateInsuranceClaim, 
  DuplicateRecoveryAction, 
  DuplicatePreventiveControl, 
  DuplicateDetectiveControl, 
  DuplicateCorrectiveControl, 
  DuplicateCompensatingControl, 
  DuplicateControlEffectiveness, 
  DuplicateControlMaturity, 
  DuplicateRiskAppetite, 
  DuplicateRiskTolerance, 
  DuplicateRiskCapacity, 
  DuplicateRiskExposure, 
  DuplicateRiskResidual, 
  DuplicateRiskInherent, 
  DuplicateRiskMitigated, 
  DuplicateRiskTransfer, 
  DuplicateRiskAcceptance, 
  DuplicateRiskAvoidance, 
  DuplicateRiskReduction, 
  DuplicateRiskSharing, 
  DuplicateRiskFinancing, 
  DuplicateRiskMonitoring, 
  DuplicateRiskReporting, 
  DuplicateRiskGovernance, 
  DuplicateRiskOwnership, 
  DuplicateRiskAccountability, 
  DuplicateRiskCulture, 
  DuplicateRiskAwareness, 
  DuplicateRiskTraining, 
  DuplicateRiskAssessment, 
  DuplicateRiskTreatment, 
  DuplicateRiskReview, 
  DuplicateRiskCommunication, 
  DuplicateRiskDocumentation, 
  DuplicateRiskRegister, 
  DuplicateRiskHeatmap, 
  DuplicateRiskDashboard, 
  DuplicateRiskKPI, 
  DuplicateRiskMetric, 
  DuplicateRiskIndicator, 
  DuplicateRiskThreshold, 
  DuplicateRiskLimit, 
  DuplicateRiskBoundary, 
  DuplicateRiskAppetiteStatement, 
  DuplicateRiskPolicy, 
  DuplicateRiskFramework, 
  DuplicateRiskMethodology, 
  DuplicateRiskStandard, 
  DuplicateRiskGuideline, 
  DuplicateRiskProcedure, 
  DuplicateRiskControl, 
  DuplicateRiskMitigationPlan, 
  DuplicateRiskTreatmentPlan, 
  DuplicateRiskResponsePlan, 
  DuplicateRiskContingencyPlan, 
  DuplicateRiskBusinessContinuityPlan, 
  DuplicateRiskDisasterRecoveryPlan, 
  DuplicateRiskIncidentResponsePlan, 
  DuplicateRiskCrisisManagementPlan, 
  DuplicateRiskCommunicationPlan, 
  DuplicateRiskStakeholderEngagementPlan, 
  DuplicateRiskTrainingPlan, 
  DuplicateRiskAwarenessPlan, 
  DuplicateRiskCulturePlan, 
  DuplicateRiskGovernancePlan, 
  DuplicateRiskMonitoringPlan, 
  DuplicateRiskReportingPlan, 
  DuplicateRiskReviewPlan, 
  DuplicateRiskDocumentationPlan, 
  DuplicateRiskRegisterPlan, 
  DuplicateRiskHeatmapPlan, 
  DuplicateRiskDashboardPlan, 
  DuplicateRiskKPIPlan, 
  DuplicateRiskMetricPlan, 
  DuplicateRiskIndicatorPlan, 
  DuplicateRiskThresholdPlan, 
  DuplicateRiskLimitPlan, 
  DuplicateRiskBoundaryPlan, 
  DuplicateRiskAppetiteStatementPlan, 
  DuplicateRiskPolicyPlan, 
  DuplicateRiskFrameworkPlan, 
  DuplicateRiskMethodologyPlan, 
  DuplicateRiskStandardPlan, 
  DuplicateRiskGuidelinePlan, 
  DuplicateRiskProcedurePlan, 
  DuplicateRiskControlPlan, 
  DuplicateRiskMitigationPlanPlan, 
  DuplicateRiskTreatmentPlanPlan, 
  DuplicateRiskResponsePlanPlan, 
  DuplicateRiskContingencyPlanPlan, 
  DuplicateRiskBusinessContinuityPlanPlan, 
  DuplicateRiskDisasterRecoveryPlanPlan, 
  DuplicateRiskIncidentResponsePlanPlan, 
  DuplicateRiskCrisisManagementPlanPlan, 
  DuplicateRiskCommunicationPlanPlan, 
  DuplicateRiskStakeholderEngagementPlanPlan, 
  DuplicateRiskTrainingPlanPlan, 
  DuplicateRiskAwarenessPlanPlan, 
  DuplicateRiskCulturePlanPlan, 
  DuplicateRiskGovernancePlanPlan, 
  DuplicateRiskMonitoringPlanPlan, 
  DuplicateRiskReportingPlanPlan, 
  DuplicateRiskReviewPlanPlan, 
  DuplicateRiskDocumentationPlanPlan, 
  DuplicateRiskRegisterPlanPlan, 
  DuplicateRiskHeatmapPlanPlan, 
  DuplicateRiskDashboardPlanPlan, 
  DuplicateRiskKPIPlanPlan, 
  DuplicateRiskMetricPlanPlan, 
  DuplicateRiskIndicatorPlanPlan, 
  DuplicateRiskThresholdPlanPlan, 
  DuplicateRiskLimitPlanPlan, 
  DuplicateRiskBoundaryPlanPlan, 
  DuplicateRiskAppetiteStatementPlanPlan, 
  DuplicateRiskPolicyPlanPlan, 
  DuplicateRiskFrameworkPlanPlan, 
  DuplicateRiskMethodologyPlanPlan, 
  DuplicateRiskStandardPlanPlan, 
  DuplicateRiskGuidelinePlanPlan, 
  DuplicateRiskProcedurePlanPlan, 
  DuplicateRiskControlPlanPlan 
} from '@/types/index';

import { auditLogger } from '@/lib/utils/audit-logger';
import { LevenshteinDistance } from './levenshtein-distance';
import { JaroWinklerSimilarity } from './jaro-winkler-similarity';
import { SoundexEncoder } from './soundex-encoder';
import { MetaphoneEncoder } from './metaphone-encoder';
import { CosineSimilarity } from './cosine-similarity';
import { TFIDFVectorizer } from './tfidf-vectorizer';
import { TemporalClusterAnalyzer } from './temporal-cluster-analyzer';
import { SupplierClusterAnalyzer } from './supplier-cluster-analyzer';
import { ContextualAnalyzer } from './contextual-analyzer';
import { PatternRecognizer } from './pattern-recognizer';
import { SA_COMPLIANCE_RULES } from '@/types/index';

export class AdvancedDuplicateDetector {
  private static readonly DUPLICATE_THRESHOLDS = {
    EXACT_MATCH: 1.00,
    VERY_HIGH_CONFIDENCE: 0.95,
    HIGH_CONFIDENCE: 0.85,
    MEDIUM_CONFIDENCE: 0.70,
    LOW_CONFIDENCE: 0.50,
    MIN_CONFIDENCE: 0.30
  };

  private static readonly DUPLICATE_WEIGHTS = {
    INVOICE_NUMBER: 0.30,
    SUPPLIER_NAME: 0.20,
    TOTAL_AMOUNT: 0.15,
    INVOICE_DATE: 0.10,
    SUPPLIER_VAT: 0.10,
    LINE_ITEMS: 0.15
  };

  // SA_COMPLIANCE_RULES is imported from @/types/index (sqlite.ts)

  private static readonly DUPLICATE_PATTERNS: DuplicatePattern[] = [
    { patternType: 'EXACT_INVOICE_NUMBER', description: 'Exact invoice number match', severity: 'CRITICAL' },
    { patternType: 'FUZZY_INVOICE_NUMBER', description: 'Fuzzy invoice number match', severity: 'HIGH' },
    { patternType: 'SAME_SUPPLIER_SAME_AMOUNT', description: 'Same supplier, same amount, different invoice number', severity: 'HIGH' },
    { patternType: 'SAME_SUPPLIER_SAME_DATE', description: 'Same supplier, same date, different invoice number', severity: 'MEDIUM' },
    { patternType: 'CROSS_SUPPLIER_DUPLICATE', description: 'Different suppliers, same invoice details (fraud pattern)', severity: 'CRITICAL' },
    { patternType: 'PARTIAL_LINE_ITEM_MATCH', description: 'Partial line item match across invoices', severity: 'LOW' },
    { patternType: 'TEMPORAL_CLUSTER', description: 'Multiple invoices from same supplier within short timeframe', severity: 'MEDIUM' },
    { patternType: 'PO_REFERENCE_DUPLICATE', description: 'Same PO reference across multiple invoices', severity: 'HIGH' }
  ];

  private static readonly RISK_LEVELS: Record<DuplicateType, DuplicateRiskLevel> = {
    EXACT: 'CRITICAL',
    FUZZY: 'HIGH',
    TEMPORAL: 'MEDIUM',
    SUPPLIER_CLUSTER: 'HIGH',
    LINE_ITEM: 'LOW',
    CROSS_SUPPLIER: 'SEVERE',
    PO_REFERENCE: 'HIGH',
    PARTIAL: 'LOW'
  };

  private static readonly MITIGATION_ACTIONS: Record<DuplicateRiskLevel, DuplicateMitigationAction[]> = {
    LOW: ['MONITOR', 'FLAG_FOR_REVIEW'],
    MEDIUM: ['MANUAL_REVIEW', 'SUPPLIER_VERIFICATION'],
    HIGH: ['HOLD_PAYMENT', 'ESCALATE_TO_MANAGER', 'SUPPLIER_CONTACT'],
    CRITICAL: ['BLOCK_PAYMENT', 'IMMEDIATE_ESCALATION', 'FRAUD_INVESTIGATION'],
    SEVERE: ['BLOCK_PAYMENT', 'IMMEDIATE_ESCALATION', 'REGULATORY_REPORTING', 'LAW_ENFORCEMENT']
  };

  /**
   * Perform comprehensive duplicate detection with multi-algorithm analysis
   * @param input - Invoice data to check for duplicates
   * @param context - Optional business context for adaptive detection
   * @returns Comprehensive duplicate check result with confidence scoring
   */
  static async checkForDuplicates(
    input: DuplicateCheckInput,
    context?: DuplicateCheckContext
  ): Promise<DuplicateCheckResult> {
    const checkId = `dup_${Date.now()}_${this.generateRandomString(12)}`;
    const checkStartTime = Date.now();
    const auditTrail: DuplicateAuditTrail[] = [];
    
    try {
      // Step 1: Validate input data quality
      auditTrail.push(this.createAuditEntry('DUPLICATE_CHECK_INITIALIZED', checkId, { input, context }));
      this.validateInput(input, checkId);
      
      // Step 2: Perform exact match detection (fast path)
      auditTrail.push(this.createAuditEntry('EXACT_MATCH_DETECTION_STARTED', checkId));
      const exactMatches = await this.detectExactMatches(input, context, checkId);
      auditTrail.push(this.createAuditEntry('EXACT_MATCH_DETECTION_COMPLETED', checkId, { exactMatchCount: exactMatches.length }));
      
      if (exactMatches.length > 0) {
        // Exact match found - return immediately with critical confidence
        const result = this.createExactMatchResult(exactMatches, checkId, checkStartTime, auditTrail);
        this.logDuplicateDetection(result, checkStartTime, Date.now());
        return result;
      }
      
      // Step 3: Perform fuzzy matching analysis
      auditTrail.push(this.createAuditEntry('FUZZY_MATCHING_STARTED', checkId));
      const fuzzyMatches = await this.detectFuzzyMatches(input, context, checkId);
      auditTrail.push(this.createAuditEntry('FUZZY_MATCHING_COMPLETED', checkId, { fuzzyMatchCount: fuzzyMatches.length }));
      
      // Step 4: Perform temporal cluster analysis
      auditTrail.push(this.createAuditEntry('TEMPORAL_CLUSTER_ANALYSIS_STARTED', checkId));
      const temporalClusters = await this.analyzeTemporalClusters(input, context, checkId);
      auditTrail.push(this.createAuditEntry('TEMPORAL_CLUSTER_ANALYSIS_COMPLETED', checkId, { clusterCount: temporalClusters.length }));
      
      // Step 5: Perform supplier cluster analysis
      auditTrail.push(this.createAuditEntry('SUPPLIER_CLUSTER_ANALYSIS_STARTED', checkId));
      const supplierClusters = await this.analyzeSupplierClusters(input, context, checkId);
      auditTrail.push(this.createAuditEntry('SUPPLIER_CLUSTER_ANALYSIS_COMPLETED', checkId, { clusterCount: supplierClusters.length }));
      
      // Step 6: Perform line item analysis
      auditTrail.push(this.createAuditEntry('LINE_ITEM_ANALYSIS_STARTED', checkId));
      const lineItemMatches = await this.analyzeLineItems(input, context, checkId);
      auditTrail.push(this.createAuditEntry('LINE_ITEM_ANALYSIS_COMPLETED', checkId, { lineItemMatchCount: lineItemMatches.length }));
      
      // Step 7: Perform contextual analysis for false positive reduction
      auditTrail.push(this.createAuditEntry('CONTEXTUAL_ANALYSIS_STARTED', checkId));
      const contextualAnalysis = await this.performContextualAnalysis(
        input,
        fuzzyMatches,
        temporalClusters,
        supplierClusters,
        lineItemMatches,
        context,
        checkId
      );
      auditTrail.push(this.createAuditEntry('CONTEXTUAL_ANALYSIS_COMPLETED', checkId, { contextualAnalysis }));
      
      // Step 8: Calculate overall confidence and determine duplicate status
      auditTrail.push(this.createAuditEntry('CONFIDENCE_CALCULATION_STARTED', checkId));
      const confidenceResult = this.calculateConfidence(
        fuzzyMatches,
        temporalClusters,
        supplierClusters,
        lineItemMatches,
        contextualAnalysis,
        checkId
      );
      auditTrail.push(this.createAuditEntry('CONFIDENCE_CALCULATION_COMPLETED', checkId, { confidenceResult }));
      
      // Step 9: Determine duplicate type and risk level
      auditTrail.push(this.createAuditEntry('DUPLICATE_TYPE_DETERMINATION_STARTED', checkId));
      const duplicateType = this.determineDuplicateType(confidenceResult, fuzzyMatches, temporalClusters, supplierClusters, checkId);
      const riskLevel = this.determineRiskLevel(duplicateType, confidenceResult.overallConfidence, checkId);
      auditTrail.push(this.createAuditEntry('DUPLICATE_TYPE_DETERMINATION_COMPLETED', checkId, { duplicateType, riskLevel }));
      
      // Step 10: Generate potential duplicates list with evidence
      auditTrail.push(this.createAuditEntry('POTENTIAL_DUPLICATES_GENERATION_STARTED', checkId));
      const potentialDuplicates = this.generatePotentialDuplicates(
        fuzzyMatches,
        temporalClusters,
        supplierClusters,
        lineItemMatches,
        confidenceResult,
        duplicateType,
        riskLevel,
        checkId
      );
      auditTrail.push(this.createAuditEntry('POTENTIAL_DUPLICATES_GENERATION_COMPLETED', checkId, { potentialDuplicateCount: potentialDuplicates.length }));
      
      // Step 11: Generate mitigation actions based on risk level
      auditTrail.push(this.createAuditEntry('MITIGATION_ACTION_GENERATION_STARTED', checkId));
      const mitigationActions = this.generateMitigationActions(riskLevel, duplicateType, checkId);
      auditTrail.push(this.createAuditEntry('MITIGATION_ACTION_GENERATION_COMPLETED', checkId, { mitigationActions }));
      
      // Step 12: Create comprehensive duplicate check result
      const result: DuplicateCheckResult = {
        checkId,
        checkTimestamp: new Date(),
        inputHash: this.generateInputHash(input),
        isDuplicate: confidenceResult.overallConfidence >= SA_COMPLIANCE_RULES.DUPLICATE_DETECTION_THRESHOLD,
        duplicateType: confidenceResult.overallConfidence >= SA_COMPLIANCE_RULES.DUPLICATE_DETECTION_THRESHOLD ? duplicateType : 'NONE',
        confidence: confidenceResult.overallConfidence,
        confidenceBreakdown: confidenceResult.breakdown,
        riskLevel: confidenceResult.overallConfidence >= SA_COMPLIANCE_RULES.DUPLICATE_DETECTION_THRESHOLD ? riskLevel : 'LOW',
        requiresAttention: confidenceResult.overallConfidence >= this.DUPLICATE_THRESHOLDS.LOW_CONFIDENCE,
        potentialDuplicates,
        mitigationActions,
        duplicatePatterns: this.identifyDuplicatePatterns(potentialDuplicates, checkId),
        investigationRequired: riskLevel === 'HIGH' || riskLevel === 'CRITICAL' || riskLevel === 'SEVERE',
        regulatoryReportingRequired: riskLevel === 'CRITICAL' || riskLevel === 'SEVERE' && SA_COMPLIANCE_RULES.SARS_DUPLICATE_REPORTING_REQUIRED,
        calculationTimestamp: new Date(),
        checkDurationMs: Date.now() - checkStartTime,
        auditTrail,
        metadata: {
          checkId,
          checkStartTime: new Date(checkStartTime),
          checkEndTime: new Date(),
          checkDurationMs: Date.now() - checkStartTime,
          saComplianceRules: SA_COMPLIANCE_RULES,
          duplicatePatterns: this.DUPLICATE_PATTERNS,
          riskLevels: this.RISK_LEVELS,
          mitigationActions: this.MITIGATION_ACTIONS
        }
      };
      
      // Step 13: Log successful duplicate detection
      this.logDuplicateDetection(result, checkStartTime, Date.now());
      
      return result;
      
    } catch (error) {
      // Log duplicate detection failure
      this.logDuplicateDetectionFailure(
        checkId,
        input,
        error instanceof Error ? error.message : String(error),
        error instanceof Error ? error.stack : undefined,
        checkStartTime,
        Date.now()
      );
      
      // Return failure result with maximum confidence (fail-safe)
      return this.createFailureResult(
        checkId,
        input,
        error instanceof Error ? error.message : 'Unknown duplicate detection error',
        Date.now() - checkStartTime,
        auditTrail
      );
    }
  }

  /**
   * Validate input data quality and completeness
   */
  private static validateInput(input: DuplicateCheckInput, checkId: string): void {
    if (!input.invoiceNumber || input.invoiceNumber.trim().length === 0) {
      throw new DuplicateDetectionException('MISSING_INVOICE_NUMBER', 'Invoice number is required for duplicate detection', checkId);
    }
    
    if (!input.supplierName || input.supplierName.trim().length === 0) {
      throw new DuplicateDetectionException('MISSING_SUPPLIER_NAME', 'Supplier name is required for duplicate detection', checkId);
    }
    
    if (!input.totalAmount || input.totalAmount <= 0) {
      throw new DuplicateDetectionException('INVALID_TOTAL_AMOUNT', 'Total amount must be greater than zero', checkId);
    }
    
    if (!input.invoiceDate) {
      throw new DuplicateDetectionException('MISSING_INVOICE_DATE', 'Invoice date is required for duplicate detection', checkId);
    }
    
    // Validate required fields per SARS compliance
    for (const field of SA_COMPLIANCE_RULES.REQUIRED_DUPLICATE_FIELDS) {
      if (!(field in input) || (input as any)[field] === null || (input as any)[field] === undefined) {
        throw new DuplicateDetectionException(
          'MISSING_REQUIRED_FIELD',
          `Required field '${field}' is missing for SARS duplicate detection compliance`,
          checkId
        );
      }
    }
  }

  /**
   * Detect exact matches in database
   */
  private static async detectExactMatches(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<ExactMatch[]> {
    // Placeholder for database query
    // In production, this would query the database for exact matches
    return [];
  }

  /**
   * Detect fuzzy matches using multiple algorithms
   */
  private static async detectFuzzyMatches(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<FuzzyMatch[]> {
    const matches: FuzzyMatch[] = [];
    
    // Invoice number fuzzy matching
    const invoiceNumberMatches = await this.fuzzyMatchInvoiceNumber(input, context, checkId);
    matches.push(...invoiceNumberMatches);
    
    // Supplier name fuzzy matching
    const supplierNameMatches = await this.fuzzyMatchSupplierName(input, context, checkId);
    matches.push(...supplierNameMatches);
    
    // Amount matching with tolerance
    const amountMatches = await this.matchAmount(input, context, checkId);
    matches.push(...amountMatches);
    
    return matches;
  }

  /**
   * Fuzzy match invoice numbers using multiple algorithms
   */
  private static async fuzzyMatchInvoiceNumber(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<FuzzyMatch[]> {
    // Placeholder for fuzzy matching logic
    // In production, this would use Levenshtein, Jaro-Winkler, etc.
    return [];
  }

  /**
   * Fuzzy match supplier names using phonetic algorithms
   */
  private static async fuzzyMatchSupplierName(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<FuzzyMatch[]> {
    // Placeholder for phonetic matching logic
    // In production, this would use Soundex, Metaphone, etc.
    return [];
  }

  /**
   * Match amounts with configurable tolerance
   */
  private static async matchAmount(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<FuzzyMatch[]> {
    // Placeholder for amount matching logic
    return [];
  }

  /**
   * Analyze temporal clusters for duplicate patterns
   */
  private static async analyzeTemporalClusters(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<TemporalCluster[]> {
    // Placeholder for temporal cluster analysis
    return [];
  }

  /**
   * Analyze supplier clusters for entity resolution
   */
  private static async analyzeSupplierClusters(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<SupplierCluster[]> {
    // Placeholder for supplier cluster analysis
    return [];
  }

  /**
   * Analyze line items for partial duplicates
   */
  private static async analyzeLineItems(
    input: DuplicateCheckInput,
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<LineItemMatch[]> {
    // Placeholder for line item analysis
    return [];
  }

  /**
   * Perform contextual analysis for false positive reduction
   */
  private static async performContextualAnalysis(
    input: DuplicateCheckInput,
    fuzzyMatches: FuzzyMatch[],
    temporalClusters: TemporalCluster[],
    supplierClusters: SupplierCluster[],
    lineItemMatches: LineItemMatch[],
    context: DuplicateCheckContext | undefined,
    checkId: string
  ): Promise<ContextualAnalysisResult> {
    // Placeholder for contextual analysis
    return {
      falsePositiveProbability: 0.0,
      contextualFactors: [],
      confidenceAdjustment: 0.0,
      recommendation: 'PROCEED_WITH_CAUTION'
    };
  }

  /**
   * Calculate overall confidence from all detection methods
   */
  private static calculateConfidence(
    fuzzyMatches: FuzzyMatch[],
    temporalClusters: TemporalCluster[],
    supplierClusters: SupplierCluster[],
    lineItemMatches: LineItemMatch[],
    contextualAnalysis: ContextualAnalysisResult,
    checkId: string
  ): ConfidenceCalculationResult {
    // Calculate weighted confidence
    let overallConfidence = 0.0;
    const breakdown: ConfidenceBreakdown = {
      fuzzyMatching: 0.0,
      temporalAnalysis: 0.0,
      supplierAnalysis: 0.0,
      lineItemAnalysis: 0.0,
      contextualAdjustment: 0.0
    };
    
    // Fuzzy matching confidence
    if (fuzzyMatches.length > 0) {
      const maxConfidence = Math.max(...fuzzyMatches.map(m => m.confidence));
      breakdown.fuzzyMatching = maxConfidence;
      overallConfidence += maxConfidence * 0.40;
    }
    
    // Temporal cluster confidence
    if (temporalClusters.length > 0) {
      const maxConfidence = Math.max(...temporalClusters.map(c => c.confidence));
      breakdown.temporalAnalysis = maxConfidence;
      overallConfidence += maxConfidence * 0.20;
    }
    
    // Supplier cluster confidence
    if (supplierClusters.length > 0) {
      const maxConfidence = Math.max(...supplierClusters.map(c => c.confidence));
      breakdown.supplierAnalysis = maxConfidence;
      overallConfidence += maxConfidence * 0.20;
    }
    
    // Line item confidence
    if (lineItemMatches.length > 0) {
      const maxConfidence = Math.max(...lineItemMatches.map(m => m.confidence));
      breakdown.lineItemAnalysis = maxConfidence;
      overallConfidence += maxConfidence * 0.20;
    }
    
    // Apply contextual adjustment
    overallConfidence += contextualAnalysis.confidenceAdjustment;
    breakdown.contextualAdjustment = contextualAnalysis.confidenceAdjustment;
    
    // Ensure confidence is within bounds
    overallConfidence = Math.min(1.0, Math.max(0.0, overallConfidence));
    
    return {
      overallConfidence,
      breakdown,
      requiresManualReview: overallConfidence >= this.DUPLICATE_THRESHOLDS.LOW_CONFIDENCE && overallConfidence < this.DUPLICATE_THRESHOLDS.HIGH_CONFIDENCE,
      isDefinitiveMatch: overallConfidence >= this.DUPLICATE_THRESHOLDS.VERY_HIGH_CONFIDENCE,
      isDefinitiveNonMatch: overallConfidence < this.DUPLICATE_THRESHOLDS.MIN_CONFIDENCE
    };
  }

  /**
   * Determine duplicate type based on detection results
   */
  private static determineDuplicateType(
    confidenceResult: ConfidenceCalculationResult,
    fuzzyMatches: FuzzyMatch[],
    temporalClusters: TemporalCluster[],
    supplierClusters: SupplierCluster[],
    checkId: string
  ): DuplicateType {
    if (confidenceResult.isDefinitiveMatch) {
      if (fuzzyMatches.some(m => m.matchType === 'INVOICE_NUMBER' && m.confidence >= 0.95)) {
        return 'EXACT';
      }
      if (fuzzyMatches.some(m => m.matchType === 'INVOICE_NUMBER' && m.confidence >= 0.85)) {
        return 'FUZZY';
      }
      if (temporalClusters.length > 0) {
        return 'TEMPORAL';
      }
      if (supplierClusters.length > 0) {
        return 'SUPPLIER_CLUSTER';
      }
      return 'FUZZY';
    }
    
    if (confidenceResult.requiresManualReview) {
      if (temporalClusters.length > 0 && supplierClusters.length > 0) {
        return 'TEMPORAL';
      }
      return 'PARTIAL';
    }
    
    return 'NONE';
  }

  /**
   * Determine risk level based on duplicate type and confidence
   */
  private static determineRiskLevel(
    duplicateType: DuplicateType,
    confidence: number,
    checkId: string
  ): DuplicateRiskLevel {
    if (duplicateType === 'NONE') return 'LOW';
    if (duplicateType === 'PARTIAL') return 'LOW';
    if (duplicateType === 'LINE_ITEM') return 'LOW';
    
    const baseRisk = this.RISK_LEVELS[duplicateType] || 'MEDIUM';
    
    if (confidence >= 0.95) {
      return baseRisk === 'MEDIUM' ? 'HIGH' : baseRisk;
    }
    
    if (confidence >= 0.85) {
      return baseRisk === 'LOW' ? 'MEDIUM' : baseRisk;
    }
    
    return baseRisk;
  }

  /**
   * Generate potential duplicates list with evidence
   */
  private static generatePotentialDuplicates(
    fuzzyMatches: FuzzyMatch[],
    temporalClusters: TemporalCluster[],
    supplierClusters: SupplierCluster[],
    lineItemMatches: LineItemMatch[],
    confidenceResult: ConfidenceCalculationResult,
    duplicateType: DuplicateType,
    riskLevel: DuplicateRiskLevel,
    checkId: string
  ): PotentialDuplicate[] {
    const duplicates: PotentialDuplicate[] = [];
    
    // Add fuzzy matches
    fuzzyMatches.forEach(match => {
      duplicates.push({
        duplicateId: match.candidateId,
        invoiceNumber: match.candidateInvoiceNumber,
        supplierName: match.candidateSupplierName,
        totalAmount: match.candidateTotalAmount,
        invoiceDate: match.candidateInvoiceDate,
        similarityScore: match.confidence,
        matchType: 'FUZZY',
        evidence: [{
          evidenceType: 'FUZZY_MATCH',
          evidenceSource: 'ALGORITHM',
          description: `Fuzzy match on ${match.matchType} with ${match.algorithm} algorithm`,
          confidence: match.confidence,
          timestamp: new Date()
        }],
        requiresInvestigation: riskLevel === 'HIGH' || riskLevel === 'CRITICAL' || riskLevel === 'SEVERE',
        investigationPriority: this.determineInvestigationPriority(riskLevel, match.confidence, checkId)
      });
    });
    
    // Add temporal clusters
    temporalClusters.forEach(cluster => {
      duplicates.push({
        duplicateId: cluster.clusterId,
        invoiceNumber: cluster.representativeInvoiceNumber,
        supplierName: cluster.supplierName,
        totalAmount: cluster.averageAmount,
        invoiceDate: cluster.centroidDate,
        similarityScore: cluster.confidence,
        matchType: 'TEMPORAL',
        evidence: [{
          evidenceType: 'TEMPORAL_CLUSTER',
          evidenceSource: 'ANALYSIS',
          description: `Temporal cluster of ${cluster.invoiceCount} invoices within ${cluster.timeWindowDays} days`,
          confidence: cluster.confidence,
          timestamp: new Date()
        }],
        requiresInvestigation: riskLevel === 'HIGH' || riskLevel === 'CRITICAL' || riskLevel === 'SEVERE',
        investigationPriority: this.determineInvestigationPriority(riskLevel, cluster.confidence, checkId)
      });
    });
    
    return duplicates.slice(0, 10); // Limit to top 10 potential duplicates
  }

  /**
   * Determine investigation priority based on risk and confidence
   */
  private static determineInvestigationPriority(
    riskLevel: DuplicateRiskLevel,
    confidence: number,
    checkId: string
  ): InvestigationPriority {
    if (riskLevel === 'SEVERE' || riskLevel === 'CRITICAL') return 'IMMEDIATE';
    if (riskLevel === 'HIGH' && confidence >= 0.90) return 'URGENT';
    if (riskLevel === 'HIGH') return 'HIGH';
    if (riskLevel === 'MEDIUM' && confidence >= 0.80) return 'MEDIUM';
    return 'LOW';
  }

  /**
   * Generate mitigation actions based on risk level
   */
  private static generateMitigationActions(
    riskLevel: DuplicateRiskLevel,
    duplicateType: DuplicateType,
    checkId: string
  ): DuplicateMitigationAction[] {
    const actions = new Set<DuplicateMitigationAction>();
    
    // Add risk-level based actions
    const riskActions = this.MITIGATION_ACTIONS[riskLevel] || [];
    riskActions.forEach(action => actions.add(action));
    
    // Add type-specific actions
    if (duplicateType === 'CROSS_SUPPLIER') {
      actions.add('FRAUD_INVESTIGATION');
      actions.add('REGULATORY_REPORTING');
    }
    
    if (duplicateType === 'PO_REFERENCE') {
      actions.add('PO_VERIFICATION');
      actions.add('CONTRACT_REVIEW');
    }
    
    return Array.from(actions);
  }

  /**
   * Identify duplicate patterns from potential duplicates
   */
  private static identifyDuplicatePatterns(
    potentialDuplicates: PotentialDuplicate[],
    checkId: string
  ): DuplicatePattern[] {
    const patterns = new Set<string>();
    
    potentialDuplicates.forEach(dup => {
      if (dup.matchType === 'FUZZY' && dup.similarityScore >= 0.95) {
        patterns.add('EXACT_INVOICE_NUMBER');
      }
      if (dup.matchType === 'TEMPORAL') {
        patterns.add('TEMPORAL_CLUSTER');
      }
    });
    
    return this.DUPLICATE_PATTERNS.filter(pattern => patterns.has(pattern.patternType));
  }

  /**
   * Create exact match result
   */
  private static createExactMatchResult(
    exactMatches: ExactMatch[],
    checkId: string,
    checkStartTime: number,
    auditTrail: DuplicateAuditTrail[]
  ): DuplicateCheckResult {
    return {
      checkId,
      checkTimestamp: new Date(),
      inputHash: '',
      isDuplicate: true,
      duplicateType: 'EXACT',
      confidence: 1.0,
      confidenceBreakdown: {
        fuzzyMatching: 1.0,
        temporalAnalysis: 1.0,
        supplierAnalysis: 1.0,
        lineItemAnalysis: 1.0,
        contextualAdjustment: 0.0
      },
      riskLevel: 'CRITICAL',
      requiresAttention: true,
      potentialDuplicates: exactMatches.map(match => ({
        duplicateId: match.candidateId,
        invoiceNumber: match.candidateInvoiceNumber,
        supplierName: match.candidateSupplierName,
        totalAmount: match.candidateTotalAmount,
        invoiceDate: match.candidateInvoiceDate,
        similarityScore: 1.0,
        matchType: 'EXACT',
        evidence: [{
          evidenceType: 'EXACT_MATCH',
          evidenceSource: 'DATABASE',
          description: 'Exact match found in database',
          confidence: 1.0,
          timestamp: new Date()
        }],
        requiresInvestigation: true,
        investigationPriority: 'IMMEDIATE'
      })),
      mitigationActions: ['BLOCK_PAYMENT', 'IMMEDIATE_ESCALATION', 'FRAUD_INVESTIGATION'],
      duplicatePatterns: [this.DUPLICATE_PATTERNS[0]], // EXACT_INVOICE_NUMBER
      investigationRequired: true,
      regulatoryReportingRequired: true,
      calculationTimestamp: new Date(),
      checkDurationMs: Date.now() - checkStartTime,
      auditTrail,
      metadata: {
        checkId,
        checkStartTime: new Date(checkStartTime),
        checkEndTime: new Date(),
        checkDurationMs: Date.now() - checkStartTime,
        saComplianceRules: SA_COMPLIANCE_RULES,
        duplicatePatterns: this.DUPLICATE_PATTERNS,
        riskLevels: this.RISK_LEVELS,
        mitigationActions: this.MITIGATION_ACTIONS
      }
    };
  }

  /**
   * Create audit trail entry
   */
  private static createAuditEntry(
    eventType: string,
    checkId: string,
    metadata?: Record<string, any>
  ): DuplicateAuditTrail {
    return {
      auditId: `dup_audit_${Date.now()}_${this.generateRandomString(8)}`,
      checkId,
      timestamp: new Date(),
      eventType,
      eventDescription: eventType.replace(/_/g, ' ').toLowerCase(),
      userId: 'system',
      ipAddress: '127.0.0.1',
      userAgent: 'CreditorFlow Duplicate Detector/3.9.2',
      metadata: metadata || {}
    };
  }

  /**
   * Generate random string for IDs
   */
  private static generateRandomString(length: number): string {
    return Array.from({ length }, () => Math.floor(Math.random() * 36).toString(36)).join('');
  }

  /**
   * Generate hash for input normalization
   */
  private static generateInputHash(input: DuplicateCheckInput): string {
    const crypto = require('crypto');
    const hash = crypto.createHash('sha256');
    hash.update(JSON.stringify({
      invoiceNumber: input.invoiceNumber,
      supplierName: input.supplierName,
      totalAmount: input.totalAmount,
      invoiceDate: input.invoiceDate,
      supplierVAT: input.supplierVAT,
      poNumber: input.poNumber,
      lineItems: input.lineItems
    }));
    return hash.digest('hex').substring(0, 32);
  }

  /**
   * Log successful duplicate detection
   */
  private static logDuplicateDetection(
    result: DuplicateCheckResult,
    startTime: number,
    endTime: number
  ): void {
    auditLogger.log(
      'DUPLICATE_DETECTION_COMPLETED',
      'invoice',
      result.checkId,
      'INFO',
      {
        checkId: result.checkId,
        isDuplicate: result.isDuplicate,
        duplicateType: result.duplicateType,
        confidence: result.confidence,
        riskLevel: result.riskLevel,
        potentialDuplicateCount: result.potentialDuplicates.length,
        checkDurationMs: endTime - startTime
      }
    );
  }

  /**
   * Log duplicate detection failure
   */
  private static logDuplicateDetectionFailure(
    checkId: string,
    input: DuplicateCheckInput,
    errorMessage: string,
    errorStack: string | undefined,
    startTime: number,
    endTime: number
  ): void {
    auditLogger.log(
      'DUPLICATE_DETECTION_FAILED',
      'invoice',
      checkId,
      'ERROR',
      {
        checkId,
        invoiceNumber: input.invoiceNumber,
        supplierName: input.supplierName,
        errorMessage,
        errorStack,
        checkDurationMs: endTime - startTime
      }
    );
  }

  /**
   * Create failure result for error handling
   */
  private static createFailureResult(
    checkId: string,
    input: DuplicateCheckInput,
    errorMessage: string,
    durationMs: number,
    auditTrail: DuplicateAuditTrail[]
  ): DuplicateCheckResult {
    return {
      checkId,
      checkTimestamp: new Date(),
      inputHash: this.generateInputHash(input),
      isDuplicate: true, // Fail-safe: assume duplicate on error
      duplicateType: 'EXACT',
      confidence: 1.0,
      confidenceBreakdown: {
        fuzzyMatching: 1.0,
        temporalAnalysis: 1.0,
        supplierAnalysis: 1.0,
        lineItemAnalysis: 1.0,
        contextualAdjustment: 0.0
      },
      riskLevel: 'SEVERE',
      requiresAttention: true,
      potentialDuplicates: [{
        duplicateId: 'ERROR_DUPLICATE',
        invoiceNumber: input.invoiceNumber,
        supplierName: input.supplierName,
        totalAmount: input.totalAmount,
        invoiceDate: input.invoiceDate,
        similarityScore: 1.0,
        matchType: 'SYSTEM_ERROR',
        evidence: [{
          evidenceType: 'SYSTEM_ERROR',
          evidenceSource: 'SYSTEM',
          description: `Duplicate detection failed: ${errorMessage}`,
          confidence: 1.0,
          timestamp: new Date()
        }],
        requiresInvestigation: true,
        investigationPriority: 'IMMEDIATE'
      }],
      mitigationActions: ['BLOCK_PAYMENT', 'IMMEDIATE_ESCALATION', 'SYSTEM_ADMIN_NOTIFICATION'],
      duplicatePatterns: [],
      investigationRequired: true,
      regulatoryReportingRequired: true,
      calculationTimestamp: new Date(),
      checkDurationMs: durationMs,
      auditTrail,
      metadata: {
        checkId,
        checkStartTime: new Date(Date.now() - durationMs),
        checkEndTime: new Date(),
        checkDurationMs: durationMs,
        saComplianceRules: SA_COMPLIANCE_RULES,
        duplicatePatterns: this.DUPLICATE_PATTERNS,
        riskLevels: this.RISK_LEVELS,
        mitigationActions: this.MITIGATION_ACTIONS
      }
    };
  }
}

// ==================== SUPPORTING INTERFACES ====================

export interface DuplicateCheckContext {
  businessUnit?: string;
  department?: string;
  supplierCategory?: string;
  historicalInvoices?: HistoricalInvoice[];
  temporalWindowDays?: number;
  confidenceThreshold?: number;
  enableContextualAnalysis?: boolean;
  enableFalsePositiveReduction?: boolean;
  customRules?: CustomDuplicateRule[];
  customWeights?: Record<string, number>;
  auditRequired?: boolean;
  regulatoryReportingEnabled?: boolean;
  investigationAutoEscalation?: boolean;
  userRiskProfile?: string;
  sessionData?: Record<string, any>;
  customAttributes?: Record<string, any>;
}

export interface HistoricalInvoice {
  invoiceId: string;
  invoiceNumber: string;
  supplierName: string;
  supplierVAT?: string;
  totalAmount: number;
  invoiceDate: Date;
  poNumber?: string;
  lineItems?: LineItem[];
  riskScore?: number;
  duplicateFlags?: string[];
}

export interface CustomDuplicateRule {
  ruleId: string;
  ruleName: string;
  ruleDescription: string;
  ruleCondition: string;
  ruleAction: string;
  rulePriority: number;
  isActive: boolean;
}

export interface ExactMatch {
  candidateId: string;
  candidateInvoiceNumber: string;
  candidateSupplierName: string;
  candidateTotalAmount: number;
  candidateInvoiceDate: Date;
  matchTimestamp: Date;
}

export interface FuzzyMatch {
  candidateId: string;
  candidateInvoiceNumber: string;
  candidateSupplierName: string;
  candidateTotalAmount: number;
  candidateInvoiceDate: Date;
  matchType: 'INVOICE_NUMBER' | 'SUPPLIER_NAME' | 'TOTAL_AMOUNT' | 'INVOICE_DATE' | 'PO_NUMBER';
  algorithm: 'LEVENSHTEIN' | 'JARO_WINKLER' | 'SOUNDEX' | 'METAPHONE' | 'COSINE' | 'TFIDF';
  confidence: number;
  similarityScore: number;
  matchDetails: Record<string, any>;
}

export interface TemporalCluster {
  clusterId: string;
  supplierName: string;
  invoiceCount: number;
  timeWindowDays: number;
  centroidDate: Date;
  representativeInvoiceNumber: string;
  averageAmount: number;
  confidence: number;
  invoices: ClusterInvoice[];
}

export interface ClusterInvoice {
  invoiceId: string;
  invoiceNumber: string;
  invoiceDate: Date;
  totalAmount: number;
}

export interface SupplierCluster {
  clusterId: string;
  supplierNames: string[];
  supplierVATs: string[];
  invoiceCount: number;
  confidence: number;
  clusterCentroid: Record<string, any>;
  suppliers: ClusterSupplier[];
}

export interface ClusterSupplier {
  supplierId: string;
  supplierName: string;
  supplierVAT?: string;
  invoiceCount: number;
}

export interface LineItemMatch {
  candidateId: string;
  candidateInvoiceNumber: string;
  candidateSupplierName: string;
  matchedLineItems: MatchedLineItem[];
  confidence: number;
  matchType: 'EXACT' | 'FUZZY' | 'SEMANTIC';
}

export interface MatchedLineItem {
  lineNumber: number;
  description: string;
  quantity: number;
  unitPrice: number;
  matchConfidence: number;
  matchType: 'EXACT' | 'FUZZY' | 'SEMANTIC';
}

export interface ContextualAnalysisResult {
  falsePositiveProbability: number;
  contextualFactors: ContextualFactor[];
  confidenceAdjustment: number;
  recommendation: 'PROCEED' | 'PROCEED_WITH_CAUTION' | 'MANUAL_REVIEW_REQUIRED' | 'BLOCK';
}

export interface ContextualFactor {
  factorType: string;
  factorDescription: string;
  factorImpact: 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL';
  confidence: number;
  evidence: string;
}

export interface ConfidenceCalculationResult {
  overallConfidence: number;
  breakdown: ConfidenceBreakdown;
  requiresManualReview: boolean;
  isDefinitiveMatch: boolean;
  isDefinitiveNonMatch: boolean;
}

export interface ConfidenceBreakdown {
  fuzzyMatching: number;
  temporalAnalysis: number;
  supplierAnalysis: number;
  lineItemAnalysis: number;
  contextualAdjustment: number;
}

export interface PotentialDuplicate {
  duplicateId: string;
  invoiceNumber: string;
  supplierName: string;
  totalAmount: number;
  invoiceDate: Date;
  similarityScore: number;
  matchType: 'EXACT' | 'FUZZY' | 'TEMPORAL' | 'SUPPLIER_CLUSTER' | 'LINE_ITEM' | 'CROSS_SUPPLIER' | 'PO_REFERENCE' | 'PARTIAL';
  evidence: DuplicateEvidence[];
  requiresInvestigation: boolean;
  investigationPriority: InvestigationPriority;
}

export type InvestigationPriority = 'IMMEDIATE' | 'URGENT' | 'HIGH' | 'MEDIUM' | 'LOW' | 'MONITOR';

export class DuplicateDetectionException extends Error {
  constructor(
    public code: string,
    public message: string,
    public checkId: string,
    public metadata?: Record<string, any>
  ) {
    super(message);
    this.name = 'DuplicateDetectionException';
  }
}

export default AdvancedDuplicateDetector;
